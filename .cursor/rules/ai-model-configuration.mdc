---
description:
globs:
alwaysApply: false
---
Description: AI model configuration for the IdeaForge project
Globs: src/agents/nodes/**/*.ts, src/services/**/*.ts, src/cli/commands/**/*.ts

# AI Model Configuration Rule

The IdeaForge project supports multiple AI models that can be selected at runtime.

## Available Models

1. **o3-mini** (default) - Cost-effective, good performance
2. **gpt-4.1** - Standard GPT-4 model
3. **gpt-4.5-preview** - Latest GPT-4 Turbo model

## Configuration Methods

### 1. Environment Variable
```bash
export AI_MODEL=gpt-4.1
./bin/ideaforge analyze project.org
```

### 2. CLI Option
```bash
./bin/ideaforge analyze project.org --model gpt-4.5-preview
./bin/ideaforge refine project.org --model o3-mini
```

### 3. Default
If no model is specified, o3-mini is used by default.

## Implementation Pattern

All AI nodes should use the `createLLM` factory function:

```typescript
import { createLLM } from '../utils/llm-factory';

export class SomeAnalysisNode {
  private llm: ChatOpenAI;
  
  constructor() {
    this.llm = createLLM(0.2, 2000); // temperature, maxTokens
  }
}
```

## Model Characteristics

- **o3-mini**: Fast, cost-effective, suitable for most tasks
- **gpt-4.1**: More capable, better reasoning, higher cost
- **gpt-4.5-preview**: Latest features, best performance, highest cost

## Examples

✅ Correct usage:
```typescript
// In a node
this.llm = createLLM(0.1, 1500);

// In CLI
./bin/ideaforge analyze project.org --model gpt-4.1
```

❌ Incorrect usage:
```typescript
// Don't hardcode models
new ChatOpenAI({ modelName: 'gpt-4' })
```
